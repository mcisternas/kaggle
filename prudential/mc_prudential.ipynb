{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prudential Life Insurance Assessment \n",
    "Develop a predictive model that accurately classifies risk\n",
    "\n",
    "More info: [kaggle competition webpage](https://www.kaggle.com/c/prudential-life-insurance-assessment)\n",
    "\n",
    "Word on the street is that people using Gradient Boosting are at the top of the leaderboard. The current version of this code demonstrates the use of sklearn's Gradient Boosting classifier to achieve a rather mediocre score. Increasing the number of estimators improves the results, but it takes over one hour per run. The next step is to use xgboost instead, which is supposed to be faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Product_Info_1</th>\n",
       "      <th>Product_Info_2</th>\n",
       "      <th>Product_Info_3</th>\n",
       "      <th>Product_Info_4</th>\n",
       "      <th>Product_Info_5</th>\n",
       "      <th>Product_Info_6</th>\n",
       "      <th>Product_Info_7</th>\n",
       "      <th>Ins_Age</th>\n",
       "      <th>Ht</th>\n",
       "      <th>...</th>\n",
       "      <th>Medical_Keyword_39</th>\n",
       "      <th>Medical_Keyword_40</th>\n",
       "      <th>Medical_Keyword_41</th>\n",
       "      <th>Medical_Keyword_42</th>\n",
       "      <th>Medical_Keyword_43</th>\n",
       "      <th>Medical_Keyword_44</th>\n",
       "      <th>Medical_Keyword_45</th>\n",
       "      <th>Medical_Keyword_46</th>\n",
       "      <th>Medical_Keyword_47</th>\n",
       "      <th>Medical_Keyword_48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D3</td>\n",
       "      <td>26</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.611940</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A2</td>\n",
       "      <td>26</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>D3</td>\n",
       "      <td>26</td>\n",
       "      <td>0.144667</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.582090</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.151709</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Product_Info_1 Product_Info_2  Product_Info_3  Product_Info_4  \\\n",
       "0   1               1             D3              26        0.487179   \n",
       "1   3               1             A2              26        0.076923   \n",
       "2   4               1             D3              26        0.144667   \n",
       "3   9               1             A1              26        0.151709   \n",
       "4  12               1             A1              26        0.076923   \n",
       "\n",
       "   Product_Info_5  Product_Info_6  Product_Info_7   Ins_Age        Ht  \\\n",
       "0               2               3               1  0.611940  0.781818   \n",
       "1               2               3               1  0.626866  0.727273   \n",
       "2               2               3               1  0.582090  0.709091   \n",
       "3               2               1               1  0.522388  0.654545   \n",
       "4               2               3               1  0.298507  0.672727   \n",
       "\n",
       "          ...          Medical_Keyword_39  Medical_Keyword_40  \\\n",
       "0         ...                           0                   0   \n",
       "1         ...                           0                   0   \n",
       "2         ...                           0                   0   \n",
       "3         ...                           0                   0   \n",
       "4         ...                           0                   0   \n",
       "\n",
       "   Medical_Keyword_41  Medical_Keyword_42  Medical_Keyword_43  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_44  Medical_Keyword_45  Medical_Keyword_46  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_47  Medical_Keyword_48  \n",
       "0                   0                   0  \n",
       "1                   0                   0  \n",
       "2                   0                   0  \n",
       "3                   1                   1  \n",
       "4                   0                   0  \n",
       "\n",
       "[5 rows x 127 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.svm\n",
    "import sklearn.ensemble\n",
    "import time\n",
    "\n",
    "def read_test_train(sample_training=False): \n",
    "    #sample training set? False: use the whole data set, otherwise, input a fraction to use (value from 0-1)\n",
    "\n",
    "    df_train = pd.read_csv('train.csv')\n",
    "    df_test = pd.read_csv('test.csv')\n",
    "    \n",
    "    if sample_training:\n",
    "        df_train = df_train.sample(frac=sample_training)\n",
    "\n",
    "    return df_train, df_test\n",
    "\n",
    "df_train, df_test = read_test_train(sample_training=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_labels_features_ids(df_train, df_test):\n",
    "    y_train = df_train[\"Response\"]\n",
    "    X_train = df_train.iloc[:,1:127]\n",
    "    X_test = df_test.iloc[:,1:127]\n",
    "    id_test = df_test['Id']\n",
    "    return y_train, X_train, X_test, id_test\n",
    "\n",
    "y_train, X_train, X_test, id_test = get_labels_features_ids(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to list features with missing values\n",
    "def listNA(X):\n",
    "    print(\"%20s \\tCount \\tPct missing\" % 'Feature')\n",
    "    for column_name, column in X.iteritems():\n",
    "        naCount = sum(column.isnull())\n",
    "        if naCount > 0:\n",
    "           print(\"%20s \\t%5d  \\t%2.2f%%\" % (column_name, naCount, 100.*naCount/X.shape[0]))\n",
    "        \n",
    "#listNA(X_train)\n",
    "    \n",
    "#fill NAs using the mean for now\n",
    "X_train.fillna(X_train.mean(), inplace=True)\n",
    "X_test.fillna(X_test.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59381, 1079), (19765, 1079))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def addDummies(X_train, X_test):    \n",
    "    \"\"\"\n",
    "    Simple function to convert the categorical variables from the Prudential\n",
    "    dataset into dummy (1/0) variables. Returns new train/test dfs\n",
    "    \"\"\"\n",
    "    \n",
    "    categoricalColNames = [\"Product_Info_1\", \"Product_Info_2\", \"Product_Info_3\", \"Product_Info_5\", \"Product_Info_6\", \"Product_Info_7\", \"Employment_Info_2\", \"Employment_Info_3\", \"Employment_Info_5\", \"InsuredInfo_1\", \"InsuredInfo_2\", \"InsuredInfo_3\", \"InsuredInfo_4\", \"InsuredInfo_5\", \"InsuredInfo_6\", \"InsuredInfo_7\", \"Insurance_History_1\", \"Insurance_History_2\", \"Insurance_History_3\", \"Insurance_History_4\", \"Insurance_History_7\", \"Insurance_History_8\", \"Insurance_History_9\", \"Family_Hist_1\", \"Medical_History_2\", \"Medical_History_3\", \"Medical_History_4\", \"Medical_History_5\", \"Medical_History_6\", \"Medical_History_7\", \"Medical_History_8\", \"Medical_History_9\", \"Medical_History_10\", \"Medical_History_11\", \"Medical_History_12\", \"Medical_History_13\", \"Medical_History_14\", \"Medical_History_16\", \"Medical_History_17\", \"Medical_History_18\", \"Medical_History_19\", \"Medical_History_20\", \"Medical_History_21\", \"Medical_History_22\", \"Medical_History_23\", \"Medical_History_25\", \"Medical_History_26\", \"Medical_History_27\", \"Medical_History_28\", \"Medical_History_29\", \"Medical_History_30\", \"Medical_History_31\", \"Medical_History_33\", \"Medical_History_34\", \"Medical_History_35\", \"Medical_History_36\", \"Medical_History_37\", \"Medical_History_38\", \"Medical_History_39\", \"Medical_History_40\", \"Medical_History_41\"]\n",
    "    newColumns = []\n",
    "    \n",
    "    X = pd.concat([X_train,X_test], axis= 0)\n",
    "    for colName in X.columns:\n",
    "        index = X.columns.get_loc(colName)\n",
    "        if colName in categoricalColNames:\n",
    "            dummies = pd.get_dummies(X.ix[:,index], prefix = colName, prefix_sep = \".\")\n",
    "            newColumns.append(dummies)\n",
    "        else:\n",
    "            newColumns.append(X.ix[:,index])\n",
    "            \n",
    "    new_X = pd.concat(newColumns, axis = 1)\n",
    "    new_X_train = new_X[:X_train.shape[0]]\n",
    "    new_X_test = new_X[X_train.shape[0]:]        \n",
    "    \n",
    "    return new_X_train, new_X_test\n",
    "\n",
    "\n",
    "def scaleFeatures(X_train, X_test):\n",
    "    \"\"\" Standardize features by removing the mean and scaling to unit variance\n",
    "    \"\"\"\n",
    "    stdscaler = sklearn.preprocessing.StandardScaler()\n",
    "    stdscaler.fit(X_train)\n",
    "    \n",
    "    X_train_sc = stdscaler.transform(X_train)\n",
    "    X_test_sc = stdscaler.transform(X_test)\n",
    "\n",
    "    return X_train_sc, X_test_sc\n",
    "\n",
    "\n",
    "X_train, X_test = addDummies(X_train, X_test)\n",
    "#X_test = addDummies(X_test)\n",
    "X_train, X_test = scaleFeatures(X_train, X_test)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping grid search for Gradient Boosting\n",
      "Elapsed time: 4107.34s\n"
     ]
    }
   ],
   "source": [
    "#Dicts with classifiers and their parameters for Grid Search CV\n",
    "\n",
    "classifiers = {\n",
    "    #'Logistic Regression': sklearn.linear_model.LogisticRegression(),\n",
    "    #'Random Forests': sklearn.ensemble.RandomForestClassifier(n_estimators=100),\n",
    "    #'SVC': sklearn.svm.SVC(C=1.0, kernel='linear', probability=False),\n",
    "    #'LinearSVC': sklearn.svm.LinearSVC(),\n",
    "    #'MultinomialNB': sklearn.naive_bayes.BernoulliNB(),\n",
    "    'Gradient Boosting': sklearn.ensemble.GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=6, subsample=0.7),\n",
    "}\n",
    "\n",
    "classifiers_gridparameters = {\n",
    "    'Logistic Regression': None,\n",
    "    'Random Forests': None,\n",
    "    'SVC': [{'kernel': ['linear'], 'C': [0.2, 0.4, 0.6, 0.8, 1.0]}],\n",
    "    'LinearSVC': {'C': [0.1, 0.4, 0.6, 1.0, 10.]},\n",
    "    'MultinomialNB': None,\n",
    "    'Gradient Boosting': None,\n",
    "    #'Gradient Boosting': {\"n_estimators\": [10, 50, 100], 'learning_rate': [0.1, 0.2, 0.3, 0.5], 'max_depth': [1, 2, 4],},\n",
    "}\n",
    "\n",
    "for clf_name, clf_notoptimized in classifiers.iteritems():\n",
    "    \n",
    "    skf = sklearn.cross_validation.StratifiedKFold(y_train, n_folds=5)\n",
    "    param_grid = classifiers_gridparameters[clf_name]\n",
    "\n",
    "    st = time.time()\n",
    "    \n",
    "    if param_grid is None:    \n",
    "        print \"Skipping grid search for %s\" %clf_name\n",
    "        clf_fitted = clf_notoptimized.fit(X_train, y_train)\n",
    "    else:\n",
    "        print \"Doing grid search for %s\" %clf_name\n",
    "        clf = sklearn.grid_search.GridSearchCV(estimator=clf_notoptimized, param_grid=param_grid, cv=skf, scoring='accuracy')\n",
    "        clf_fitted = clf.fit(X_train, y_train).best_estimator_\n",
    "        clf_optimal_params = clf.best_params_\n",
    "        print \"Best parameters:\", clf_optimal_params\n",
    "    \n",
    "    #scores = sklearn.cross_validation.cross_val_score(clf_fitted, X_train, y_train, cv=skf, scoring='accuracy')\n",
    "    #print(\"CV Accuracy: %0.4f (+/- %0.4f) %s\" % (scores.mean(), scores.std(), clf_name))\n",
    "    \n",
    "    elapsed_time = time.time() - st\n",
    "    print(\"Elapsed time: %.2fs\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = clf_fitted.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = id_test.to_frame()\n",
    "submission[\"Response\"] = y_pred\n",
    "submission.to_csv('pred_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
